{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0376496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = \"heyhey.hey\"\n",
    "\n",
    "testing.suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268dac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## We need to link to the datasets. These are too large to put on github, perhaps we should set up a dvc?\n",
    "# !! UPDATE PATHS AS NEEDED  !!\n",
    "# Matti here, saving his paths yeehaw\n",
    "# C:\\Users\\mhm25\\Desktop\\ITU\\6thSemester\\bachelorproj\\data\\BACI_sets    (or acled_sets, or gravity_sets)\n",
    "\n",
    "#BACI_folder_path_init = r\"C:\\Users\\mhm25\\Desktop\\ITU\\6thSemester\\bachelorproj\\data\\BACI_sets\"\n",
    "#BACI_folder_path = Path(BACI_folder_path_init).as_posix()\n",
    "\n",
    "ACLED_folder_path_init = r\"data/acled_sets\"\n",
    "ACLED_folder_path = Path(ACLED_folder_path_init).as_posix()\n",
    "\n",
    "Gravity_folder_path_init = r\"data/gravity_sets\"\n",
    "Gravity_folder_path = Path(Gravity_folder_path_init).as_posix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff73b62",
   "metadata": {},
   "source": [
    "## Combining all of ACLED Africa and Gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5c0895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2g/rflxz6zx1ss5_l2vhx2ypzl00000gn/T/ipykernel_66428/2324208560.py:7: DtypeWarning: Columns (40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_g = pd.read_csv(gravity)\n"
     ]
    }
   ],
   "source": [
    "# New link - We should combine all ACLED data from Africa with the Gravity dataset\n",
    "\n",
    "acled_af = f\"{ACLED_folder_path}/africa_acled.csv\"\n",
    "gravity = f\"{Gravity_folder_path}/Gravity_V202211.csv\"\n",
    "\n",
    "df_a = pd.read_csv(acled_af)\n",
    "df_g = pd.read_csv(gravity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feb75d5",
   "metadata": {},
   "source": [
    "### 01. Prepare ACLED Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can filter to the relevant columns we want - More can be added here, but update dummy code below if need be\n",
    "#   inter1 is the perpetrator, inter2 is the target\n",
    "df_a_filter = df_a[[\"country\", \"year\", \"disorder_type\", \"event_type\", \"inter1\", \"inter2\", \"fatalities\"]\n",
    "].copy()\n",
    "\n",
    "# We save a list of all unique possible values for the columns for future use and reference.\n",
    "country_list = df_a_filter[\"country\"].unique()\n",
    "country_list.sort()\n",
    "disorder_types = df_a_filter[\"disorder_type\"].unique()\n",
    "event_types = df_a_filter[\"event_type\"].unique()\n",
    "attack_groups = df_a_filter[\"inter1\"].unique()\n",
    "target_groups = df_a_filter[\"inter2\"].unique()\n",
    "\n",
    "# Now we need to link the countries to the tags in Gravity\n",
    "\n",
    "df_a_filter.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f25f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_a_filter.copy()\n",
    "\n",
    "# We create dummy values for each type of disorder, event, attackers and target\n",
    "dummies = pd.get_dummies(\n",
    "    df[['disorder_type', 'event_type', 'inter1', 'inter2']],\n",
    "    prefix=['disorder', 'event', 'perpetrator', 'target']\n",
    ")\n",
    "\n",
    "# We add the numeric columns back to the dummy dataset\n",
    "dummies['fatalities'] = df['fatalities']\n",
    "dummies['country'] = df['country']\n",
    "dummies['year'] = df['year']\n",
    "\n",
    "# Now we can group by country and year, and sum over the dummy categories. Perfect!\n",
    "result = dummies.groupby(['country', 'year']).sum().reset_index()\n",
    "\n",
    "## We want to map the countries from ACLED onto the iso names from the Gravity dataset.\n",
    "country_iso_dict = {\n",
    "    \"Algeria\": \"DZA\", \"Angola\": \"AGO\", 'Benin': \"BEN\", 'Botswana': \"BWA\", 'Burkina Faso': \"BFA\", \"Burundi\": \"BDI\", 'Cameroon': \"CMR\", 'Cape Verde': \"CPV\",\n",
    "    \"Central African Republic\": \"CAF\", 'Chad': \"TCD\", 'Comoros': \"COM\", 'Democratic Republic of Congo': \"COD\", 'Djibouti': \"DJI\", 'Egypt': \"EGY\",\n",
    "    'Equatorial Guinea': \"GNQ\", 'Eritrea': \"ERI\", 'Ethiopia': \"ETH\", 'Gabon': \"GAB\",'Gambia': \"GMB\", 'Ghana': \"GHA\", 'Guinea': \"GIN\", 'Guinea-Bissau': \"GNB\", \n",
    "    'Ivory Coast': \"CIV\", 'Kenya': \"KEN\", 'Lesotho': \"LSO\", 'Liberia': \"LBR\", 'Libya': \"LBY\", 'Madagascar': \"MDG\", 'Malawi': \"MWI\",'Mali': \"MLI\", \n",
    "    'Mauritania': \"MRT\", 'Mauritius': \"MUS\", 'Mayotte': \"MYT\", 'Morocco': \"MAR\",'Mozambique': \"MOZ\", 'Namibia': \"NAM\", 'Niger': \"NER\", 'Nigeria': \"NGA\", \n",
    "    'Republic of Congo': \"COG\", 'Reunion': \"REU\", 'Rwanda': \"RWA\", 'Saint Helena, Ascension and Tristan da Cunha': \"SHN\", 'Sao Tome and Principe': \"STP\", \n",
    "    'Senegal': \"SEN\", 'Seychelles': \"SYC\", 'Sierra Leone': \"SLE\", 'Somalia': \"SOM\", 'South Africa': \"ZAF\", 'South Sudan': \"SSD\", 'Sudan': \"SDN\", \n",
    "    'Tanzania': \"TZA\", 'Togo': \"TGO\", 'Tunisia': \"TUN\", 'Uganda': \"UGA\", 'Zambia': \"ZMB\", 'Zimbabwe': \"ZWE\", 'eSwatini': \"SWZ\"\n",
    "}\n",
    "\n",
    "# We update the dataframe to have a new column for the iso-tags.\n",
    "result[\"iso\"] = result[\"country\"].map(country_iso_dict)\n",
    "\n",
    "# ACLED is now ready for merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebcae88",
   "metadata": {},
   "source": [
    "### 02. Clean up Gravity and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4d9488d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'country_id_o', 'country_id_d', 'iso3_o', 'iso3_d', 'iso3num_o',\n",
       "       'iso3num_d', 'country_exists_o', 'country_exists_d',\n",
       "       'gmt_offset_2020_o', 'gmt_offset_2020_d', 'distw_harmonic',\n",
       "       'distw_arithmetic', 'distw_harmonic_jh', 'distw_arithmetic_jh', 'dist',\n",
       "       'main_city_source_o', 'main_city_source_d', 'distcap', 'contig',\n",
       "       'diplo_disagreement', 'scaled_sci_2021', 'comlang_off', 'comlang_ethno',\n",
       "       'comcol', 'col45', 'legal_old_o', 'legal_old_d', 'legal_new_o',\n",
       "       'legal_new_d', 'comleg_pretrans', 'comleg_posttrans',\n",
       "       'transition_legalchange', 'comrelig', 'heg_o', 'heg_d', 'col_dep_ever',\n",
       "       'col_dep', 'col_dep_end_year', 'col_dep_end_conflict', 'empire',\n",
       "       'sibling_ever', 'sibling', 'sever_year', 'sib_conflict', 'pop_o',\n",
       "       'pop_d', 'gdp_o', 'gdp_d', 'gdpcap_o', 'gdpcap_d', 'pop_source_o',\n",
       "       'pop_source_d', 'gdp_source_o', 'gdp_source_d', 'gdp_ppp_o',\n",
       "       'gdp_ppp_d', 'gdpcap_ppp_o', 'gdpcap_ppp_d', 'pop_pwt_o', 'pop_pwt_d',\n",
       "       'gdp_ppp_pwt_o', 'gdp_ppp_pwt_d', 'gatt_o', 'gatt_d', 'wto_o', 'wto_d',\n",
       "       'eu_o', 'eu_d', 'fta_wto', 'fta_wto_raw', 'rta_coverage', 'rta_type',\n",
       "       'entry_cost_o', 'entry_cost_d', 'entry_proc_o', 'entry_proc_d',\n",
       "       'entry_time_o', 'entry_time_d', 'entry_tp_o', 'entry_tp_d',\n",
       "       'tradeflow_comtrade_o', 'tradeflow_comtrade_d', 'tradeflow_baci',\n",
       "       'manuf_tradeflow_baci', 'tradeflow_imf_o', 'tradeflow_imf_d'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_g.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e604a1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdpcap_ppp\n",
      "wto\n",
      "eu\n",
      "entry_tp\n"
     ]
    }
   ],
   "source": [
    "target = [\"iso3_o\", \"iso3_d\", \"country_exists_o\", \"country_exists_d\", \"distw_harmonic\", \"distw_arithmetic\", \"dist\", \"distcap\", \"diplo_disagreement\", \"scaled_sci_2021\", \"comlang_off\", \"comlang_ethno\", \"comleg_posttrans\", \"comrelig\", \"heg_o\", \"heg_d\", \"col_dep_ever\", \"col_dep\", \"col_dep_end_conflict\", \"sibling_ever\", \"sibling\", \"sever_year\", \"gdpcap_ppp\", \"wto\", \"eu\", \"fta_wto\", \"rta_type\", \"entry_tp\", \"tradeflow_comtrade_o\", \"tradeflow_comtrade_d\", \"tradeflow_baci\", \"manuf_tradeflow_baci\", \"tradeflow_imf_o\", \"tradeflow_imf_d\"]\n",
    "emp = []\n",
    "for i in df_g.columns:\n",
    "    if i in target:\n",
    "        emp.append(i)\n",
    "\n",
    "for i in target:\n",
    "    if i not in emp:\n",
    "        print(i)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9e05991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>iso3_o</th>\n",
       "      <th>iso3_d</th>\n",
       "      <th>country_exists_o</th>\n",
       "      <th>country_exists_d</th>\n",
       "      <th>distw_harmonic</th>\n",
       "      <th>distw_arithmetic</th>\n",
       "      <th>dist</th>\n",
       "      <th>distcap</th>\n",
       "      <th>diplo_disagreement</th>\n",
       "      <th>...</th>\n",
       "      <th>fta_wto</th>\n",
       "      <th>rta_type</th>\n",
       "      <th>entry_tp_o</th>\n",
       "      <th>entry_tp_d</th>\n",
       "      <th>tradeflow_comtrade_o</th>\n",
       "      <th>tradeflow_comtrade_d</th>\n",
       "      <th>tradeflow_baci</th>\n",
       "      <th>manuf_tradeflow_baci</th>\n",
       "      <th>tradeflow_imf_o</th>\n",
       "      <th>tradeflow_imf_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1948</td>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949</td>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950</td>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1951</td>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1952</td>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year iso3_o iso3_d  country_exists_o  country_exists_d  distw_harmonic  \\\n",
       "0  1948    ABW    ABW                 0                 0             NaN   \n",
       "1  1949    ABW    ABW                 0                 0             NaN   \n",
       "2  1950    ABW    ABW                 0                 0             NaN   \n",
       "3  1951    ABW    ABW                 0                 0             NaN   \n",
       "4  1952    ABW    ABW                 0                 0             NaN   \n",
       "\n",
       "   distw_arithmetic  dist  distcap  diplo_disagreement  ...  fta_wto  \\\n",
       "0               NaN   NaN      NaN                 NaN  ...      NaN   \n",
       "1               NaN   NaN      NaN                 NaN  ...      NaN   \n",
       "2               NaN   NaN      NaN                 NaN  ...      NaN   \n",
       "3               NaN   NaN      NaN                 NaN  ...      NaN   \n",
       "4               NaN   NaN      NaN                 NaN  ...      NaN   \n",
       "\n",
       "   rta_type  entry_tp_o  entry_tp_d  tradeflow_comtrade_o  \\\n",
       "0       NaN         NaN         NaN                   NaN   \n",
       "1       NaN         NaN         NaN                   NaN   \n",
       "2       NaN         NaN         NaN                   NaN   \n",
       "3       NaN         NaN         NaN                   NaN   \n",
       "4       NaN         NaN         NaN                   NaN   \n",
       "\n",
       "   tradeflow_comtrade_d  tradeflow_baci  manuf_tradeflow_baci  \\\n",
       "0                   NaN             NaN                   NaN   \n",
       "1                   NaN             NaN                   NaN   \n",
       "2                   NaN             NaN                   NaN   \n",
       "3                   NaN             NaN                   NaN   \n",
       "4                   NaN             NaN                   NaN   \n",
       "\n",
       "   tradeflow_imf_o  tradeflow_imf_d  \n",
       "0              NaN              NaN  \n",
       "1              NaN              NaN  \n",
       "2              NaN              NaN  \n",
       "3              NaN              NaN  \n",
       "4              NaN              NaN  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we can start cleaning up the Gravity dataset to prepare for combining with the ACLED dataframe above\n",
    "\n",
    "df_g_filter = df_g[[\"year\", \"iso3_o\", \"iso3_d\", \"country_exists_o\", \"country_exists_d\", \"distw_harmonic\", \"distw_arithmetic\", \"dist\", \"distcap\", \"diplo_disagreement\", \"scaled_sci_2021\", \"comlang_off\", \"comlang_ethno\", \"comleg_posttrans\", \"comrelig\", \"heg_o\", \"heg_d\", \"col_dep_ever\", \"col_dep\", \"col_dep_end_conflict\", \"sibling_ever\", \"sibling\", \"sever_year\", \"gdpcap_ppp_o\", \"gdpcap_ppp_d\", \"wto_o\", \"wto_d\", \"eu_o\", \"eu_d\",\"fta_wto\", \"rta_type\", \"entry_tp_o\", \"entry_tp_d\", \"tradeflow_comtrade_o\", \"tradeflow_comtrade_d\", \"tradeflow_baci\", \"manuf_tradeflow_baci\", \"tradeflow_imf_o\", \"tradeflow_imf_d\"]\n",
    "]\n",
    "\n",
    "display(df_g_filter.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
